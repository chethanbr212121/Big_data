>>> spark.sql('show databases').count()

>>> spark.sql('show databases').show()

>>> spark.sql('select * from test.happiness_index limit 10').show()

>>> spark.sql('select count(*) from test.happiness_index').show()

>>> spark.sql('show functions').show(50)

>>> spark.sql('desc happiness_index').show()

>>> spark.sql('desc extended happiness_index').show()

>>> spark.sql("CREATE TABLE IF NOT EXISTS employees  (id INT, name STRING, age INT, sales_amt INT, city STRING, state STRING)") 

>>> spark.sql("INSERT INTO TABLE employees VALUES  (1, 'John', 28, 100, 'LA', 'CA'), (2, 'Jane', 32, 200, 'NY', 'NY'), (3, 'David', 45, 150, 'LA', 'CA'), (4, 'Lisa', 23, 300, 'NY', 'NY'), (5, 'Mike', 38, 250, 'SF', 'CA')") 
  
  
 spark.sql("CREATE TABLE students (name VARCHAR(64), address VARCHAR(64)) USING PARQUET PARTITIONED BY (student_id INT)")
 
 spark.sql("INSERT OVERWRITE TABLE zipcodes PARTITION(state) SELECT RecordNumber,Country,City,Zipcode,State from  zipcodes_tmp")






----------------------------------------------------------------------------------------------------------------------------------------------

----> Read CSV file.
--> ap_csv_data_3 = spark.read.format("csv").load(path="hdfs://localhost:50000/chetu/AdventureWorksCustomers.csv", header=True, sep="," , InferSchema=True)

--> df_1 = spark.read.format("csv").option("header",True).load(path="hdfs://localhost:50000/chetu/AdventureWorksCustomers.csv")

--> df_1 = spark.read.format("csv").option("header",True).option("Inferschema", True).load(path="hdfs://localhost:50000/chetu/AdventureWorksCustomers.csv")

--> df_1 = spark.read.format("csv").option("header",True).option("Inferschema", True).option("sep",",").load(path="hdfs://localhost:50000/chetu/AdventureWorksCustomers.csv")

--> df_2 = spark.read.format("csv").options(header="True", Inferschema="True", sep=",").load(path="hdfs://localhost:50000/chetu/AdventureWorksCustomers.csv")
























